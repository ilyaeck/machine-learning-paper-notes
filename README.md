# machine-learning-paper-notes
Keep track of machine/deep learning lit, language-related and beyond

### Natural Language Understadning 
* [Neural Machine Translation by Jointly Learning to Align and Translate](https://github.com/ilyaeck/machine-learning-paper-notes/blob/master/notes/joint-align-translate.md) [[ICLR 2015 via ArXiv]](https://arxiv.org/abs/1409.0473)<br>
Tags: translation, seq2seq, attention
* End-to-End Reinforcement Learning of Dialogue Agents for Information Access [[arXiv]](https://arxiv.org/abs/1609.00777) <br>
Tags: RL, dialogue, QA
* Hierarchical Multiscale Recurrent Neural Networks [[arXiv]] (http://arxiv.org/abs/1609.01704) <br>
  Tags: seq, hierarchical
* A Decomposable Attention Model for Natural Language Inference [[arXiv]](https://arxiv.org/abs/1606.01933) <br>
  Tags: NLI, attention
* WikiReading: a Novel Large Scale Language Undersatnding Task Over Wikipedia [summarized by Andrej Karpathy](https://github.com/karpathy/paper-notes/blob/master/wikireading.md) [[paper]](http://www.aclweb.org/anthology/P/P16/P16-1145.pdf)
  Tags: QA, data, benchmarks 
* End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning [[arXiv]](https://arxiv.org/abs/1606.01269)<br>
  Tags: RL, dialogue
* An Ensemble Method to Produce High-Quality Word Embeddings [[Github]](https://github.com/LuminosoInsight/conceptnet-numberbatch)<br>
  Tags: conceptnet, word embeddings, semantics, ensemble
* Exploring the Limits of Language Modeling [[arXiv]](https://arxiv.org/abs/1602.02410) [[code+data]](https://github.com/tensorflow/models/tree/master/lm_1b) <br>
  Tags: real-world language model 
* Neural Machine Translation in Linear Time [[arXiv]](https://arxiv.org/abs/1610.10099) <br>
  Tags: language model, translation, long-range dependencies
* A Fast Unified Model for Parsing and Language Understanding [[arXiv]](http://arxiv.org/abs/1603.06021) <br>
  Tags: language model, parsing, NLI
* Context2vec: Learning Generic Context Embedding
with Bidirectional LSTM [[ConLL2016]](http://u.cs.biu.ac.il/~melamuo/publications/context2vec_conll16.pdf)
  Tags: seq, compositionality, language model 
* Layers of Interpretation: On Grammar and Compositionality [[ACL2016]](http://aclweb.org/anthology/W/W15/W15-0128.pdf) <br>
  Tags: compositionality


### Fundamental Deep Learning 
* Learning to learn by gradient descent - by gradient descent! [[arXiv]](https://arxiv.org/abs/1606.04474) <br> 
* Incremental Sequence Learning [[Website+paper]](https://edwin-de-jong.github.io/blog/isl/incremental-sequence-learning.html) <br>
* Learning to learn [[code]](https://github.com/deepmind/learning-to-learn) [[arXiv]](https://arxiv.org/abs/1606.04474)

### Computer Vision 
* VQA: Visual Question Answering [[paper]](http://visualqa.org/VQA_ICCV2015.pdf) <br>
  Tags: QA, multimodal 


### Misc 
* WaveNet: A Generative Model for Raw Audio [[website + paper]](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)
* Learning to Communicate with Deep Multi-Agent Reinforcement Learning [[Github]](https://github.com/iassael/learning-to-communicate) <br>
  Tags: RL, multi-agent 
